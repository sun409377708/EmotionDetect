#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¡¨æƒ…è¯†åˆ«æ¨¡å‹è®­ç»ƒè„šæœ¬ - ä¿®æ­£ç‰ˆ
åŸºäºFER2013æ•°æ®é›†ï¼Œä½¿ç”¨CNNè¿›è¡Œ7ç§è¡¨æƒ…åˆ†ç±»
æœ€ç»ˆè¾“å‡ºTFLiteæ ¼å¼æ¨¡å‹
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
import time
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®éšæœºç§å­ç¡®ä¿ç»“æœå¯å¤ç°
np.random.seed(42)
tf.random.set_seed(42)

print("ğŸš€ å¼€å§‹è¡¨æƒ…è¯†åˆ«æ¨¡å‹è®­ç»ƒ...")
print(f"TensorFlowç‰ˆæœ¬: {tf.__version__}")
print(f"GPUè®¾å¤‡: {tf.config.list_physical_devices('GPU')}")

class EmotionRecognitionTrainer:
    def __init__(self, input_shape=(48, 48, 1), num_classes=7):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = None
        self.emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']
        
    def preprocess_data(self, csv_file_path):
        """é¢„å¤„ç†FER2013æ•°æ®é›†"""
        print("æ­£åœ¨åŠ è½½å’Œé¢„å¤„ç†æ•°æ®...")
        start_time = time.time()
        
        # è¯»å–CSVæ–‡ä»¶
        df = pd.read_csv(csv_file_path)
        print(f"æ•°æ®é›†å¤§å°: {len(df)} ä¸ªæ ·æœ¬")
        
        # è§£æåƒç´ æ•°æ®
        pixels = df['pixels'].tolist()
        images = []
        
        for i, pixel_sequence in enumerate(pixels):
            if i % 5000 == 0:
                print(f"å¤„ç†è¿›åº¦: {i}/{len(pixels)}")
            
            # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºnumpyæ•°ç»„
            image = np.fromstring(pixel_sequence, dtype=int, sep=' ')
            # é‡å¡‘ä¸º48x48å¹¶å½’ä¸€åŒ–
            image = image.reshape(48, 48) / 255.0
            # æ·»åŠ é€šé“ç»´åº¦
            image = np.expand_dims(image, axis=-1)
            images.append(image)
        
        images = np.array(images)
        labels = df['emotion'].values
        
        # æ ‡ç­¾ç¼–ç ä¸ºone-hot
        labels = to_categorical(labels, self.num_classes)
        
        print(f"å›¾åƒå½¢çŠ¶: {images.shape}")
        print(f"æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
        print(f"æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.1f} ç§’")
        
        return images, labels
    
    def create_model(self):
        """åˆ›å»ºCNNæ¨¡å‹æ¶æ„"""
        print("åˆ›å»ºæ¨¡å‹æ¶æ„...")
        
        model = tf.keras.Sequential([
            # ç¬¬ä¸€å±‚å·ç§¯å—
            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=self.input_shape),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Dropout(0.25),
            
            # ç¬¬äºŒå±‚å·ç§¯å—
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Dropout(0.25),
            
            # ç¬¬ä¸‰å±‚å·ç§¯å—
            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
            tf.keras.layers.Dropout(0.25),
            
            # å…¨è¿æ¥å±‚
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dropout(0.5),
            
            # è¾“å‡ºå±‚
            tf.keras.layers.Dense(self.num_classes, activation='softmax')
        ])
        
        self.model = model
        print("æ¨¡å‹åˆ›å»ºå®Œæˆ")
        return model
    
    def compile_model(self, learning_rate=0.001):
        """ç¼–è¯‘æ¨¡å‹"""
        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
        
        self.model.compile(
            optimizer=optimizer,
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        print("æ¨¡å‹ç¼–è¯‘å®Œæˆ")
        return self.model
    
    def train_model(self, X_train, y_train, X_val, y_val, epochs=50, batch_size=32):
        """è®­ç»ƒæ¨¡å‹"""
        print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        
        # æ•°æ®å¢å¼º
        train_datagen = ImageDataGenerator(
            rotation_range=20,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest'
        )
        
        val_datagen = ImageDataGenerator()
        
        train_generator = train_datagen.flow(
            X_train, y_train,
            batch_size=batch_size,
            shuffle=True
        )
        
        val_generator = val_datagen.flow(
            X_val, y_val,
            batch_size=batch_size,
            shuffle=False
        )
        
        # å›è°ƒå‡½æ•°
        callbacks = [
            ModelCheckpoint(
                'best_emotion_model.h5',
                monitor='val_accuracy',
                save_best_only=True,
                mode='max',
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=8,
                min_lr=1e-7,
                verbose=1
            ),
            EarlyStopping(
                monitor='val_accuracy',
                patience=15,
                restore_best_weights=True,
                verbose=1
            )
        ]
        
        # è®­ç»ƒæ¨¡å‹
        history = self.model.fit(
            train_generator,
            steps_per_epoch=len(X_train) // batch_size,
            epochs=epochs,
            validation_data=val_generator,
            validation_steps=len(X_val) // batch_size,
            callbacks=callbacks,
            verbose=1
        )
        
        print("è®­ç»ƒå®Œæˆ")
        return history
    
    def evaluate_model(self, X_test, y_test):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        print("è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
        
        # é¢„æµ‹
        predictions = self.model.predict(X_test)
        predicted_classes = np.argmax(predictions, axis=1)
        true_classes = np.argmax(y_test, axis=1)
        
        # è®¡ç®—å‡†ç¡®ç‡
        accuracy = np.mean(predicted_classes == true_classes)
        print(f"æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.4f}")
        
        # åˆ†ç±»æŠ¥å‘Š
        from sklearn.metrics import classification_report, confusion_matrix
        print("\nåˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(true_classes, predicted_classes, 
                                  target_names=self.emotion_labels))
        
        return accuracy
    
    def convert_to_tflite(self, model_path='best_emotion_model.h5', 
                         output_path='emotion_model.tflite', quantize=True):
        """è½¬æ¢æ¨¡å‹ä¸ºTFLiteæ ¼å¼"""
        print("è½¬æ¢æ¨¡å‹ä¸ºTFLiteæ ¼å¼...")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        model = tf.keras.models.load_model(model_path)
        
        # åˆ›å»ºè½¬æ¢å™¨
        converter = tf.lite.TFLiteConverter.from_keras_model(model)
        
        if quantize:
            # å¯ç”¨é‡åŒ–ä¼˜åŒ–
            converter.optimizations = [tf.lite.Optimize.DEFAULT]
            print("å¯ç”¨æ¨¡å‹é‡åŒ–...")
        
        # è½¬æ¢
        tflite_model = converter.convert()
        
        # ä¿å­˜
        with open(output_path, 'wb') as f:
            f.write(tflite_model)
        
        # æ£€æŸ¥æ¨¡å‹å¤§å°
        original_size = os.path.getsize(model_path) / (1024 * 1024)
        tflite_size = os.path.getsize(output_path) / (1024 * 1024)
        
        print(f"åŸå§‹æ¨¡å‹å¤§å°: {original_size:.2f} MB")
        print(f"TFLiteæ¨¡å‹å¤§å°: {tflite_size:.2f} MB")
        print(f"å‹ç¼©æ¯”: {original_size/tflite_size:.2f}x")
        
        return output_path

def main():
    print("=" * 60)
    print("è¡¨æƒ…è¯†åˆ«æ¨¡å‹è®­ç»ƒå¼€å§‹")
    print("=" * 60)
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = EmotionRecognitionTrainer()
    
    # é¢„å¤„ç†æ•°æ®
    X, y = trainer.preprocess_data('archive/fer2013/fer2013.csv')
    
    # åˆ†å‰²æ•°æ®é›†
    print("åˆ†å‰²æ•°æ®é›†...")
    X_train, X_temp, y_train, y_temp = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
    )
    
    print(f"è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
    print(f"éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬")
    print(f"æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
    
    # åˆ›å»ºå’Œç¼–è¯‘æ¨¡å‹
    model = trainer.create_model()
    trainer.compile_model()
    
    # æ˜¾ç¤ºæ¨¡å‹æ¶æ„
    model.summary()
    
    # è®­ç»ƒæ¨¡å‹
    history = trainer.train_model(
        X_train, y_train, X_val, y_val,
        epochs=50, batch_size=32
    )
    
    # è¯„ä¼°æ¨¡å‹
    accuracy = trainer.evaluate_model(X_test, y_test)
    
    # è½¬æ¢ä¸ºTFLite
    tflite_path = trainer.convert_to_tflite()
    
    print("\n" + "=" * 60)
    print("è®­ç»ƒå®Œæˆï¼")
    print("=" * 60)
    print(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜ä¸º: best_emotion_model.h5")
    print(f"TFLiteæ¨¡å‹å·²ä¿å­˜ä¸º: {tflite_path}")
    print(f"æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {accuracy:.4f}")
    print("=" * 60)

if __name__ == "__main__":
    main() 