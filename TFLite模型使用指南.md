# TFLiteæ¨¡å‹ä½¿ç”¨æŒ‡å—

## ğŸ“¦ å¯ç”¨æ¨¡å‹

å½“å‰ç›®å½•åŒ…å«ä»¥ä¸‹TFLiteæ¨¡å‹ï¼š

| æ¨¡å‹æ–‡ä»¶ | å¤§å° | æ¨èåœºæ™¯ | ç‰¹ç‚¹ |
|---------|------|----------|------|
| `tflite_models/emotion_model_dynamic.tflite` | 0.68 MB | ğŸŒ **Web/æœåŠ¡å™¨** | æœ€ä½³å¹³è¡¡ |
| `tflite_models/emotion_model_int8.tflite` | 0.69 MB | ğŸ“± **ç§»åŠ¨ç«¯** | æœ€å¿«é€Ÿåº¦ |
| `tflite_models/emotion_model_basic.tflite` | 2.61 MB | ğŸ¯ **é«˜ç²¾åº¦** | æ— æŸè½¬æ¢ |
| `tflite_models/emotion_model_float16.tflite` | 1.32 MB | ğŸ”§ **GPUä¼˜åŒ–** | GPUå‹å¥½ |
| `emotion_model.tflite` | 0.68 MB | ğŸ“œ **åŸæœ‰æ¨¡å‹** | å‘åå…¼å®¹ |

## ğŸš€ å¿«é€Ÿé€‰æ‹©æŒ‡å—

### ğŸ‘‰ æ¨èé…ç½®

**ç”Ÿäº§ç¯å¢ƒé¦–é€‰**: `emotion_model_dynamic.tflite`
- æœ€ä½³çš„æ€§èƒ½/ç²¾åº¦/å¤§å°å¹³è¡¡
- æ¨ç†æ—¶é—´: 0.90ms
- ç²¾åº¦æŸå¤±: å¾®å°

**ç§»åŠ¨åº”ç”¨é¦–é€‰**: `emotion_model_int8.tflite`  
- æœ€å¿«æ¨ç†é€Ÿåº¦: 0.84ms
- æœ€ä½å†…å­˜å ç”¨
- é€‚åˆå®æ—¶åº”ç”¨

## ğŸ’» ä»£ç ç¤ºä¾‹

### Pythonæ¨ç†ä»£ç 

```python
import tensorflow as tf
import numpy as np

def load_tflite_model(model_path):
    """åŠ è½½TFLiteæ¨¡å‹"""
    interpreter = tf.lite.Interpreter(model_path=model_path)
    interpreter.allocate_tensors()
    return interpreter

def predict_emotion(interpreter, image):
    """ä½¿ç”¨TFLiteæ¨¡å‹é¢„æµ‹è¡¨æƒ…"""
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    # é¢„å¤„ç†å›¾åƒ (å‡è®¾imageæ˜¯48x48çš„numpyæ•°ç»„)
    if input_details[0]['dtype'] == np.int8:
        # INT8æ¨¡å‹éœ€è¦ç‰¹æ®Šé¢„å¤„ç†
        input_data = ((image - 0.5) * 255).astype(np.int8)
    else:
        # Float32æ¨¡å‹
        input_data = image.astype(np.float32)
    
    # æ·»åŠ batchç»´åº¦
    input_data = np.expand_dims(input_data, axis=0)
    
    # æ¨ç†
    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()
    output_data = interpreter.get_tensor(output_details[0]['index'])
    
    # å¤„ç†è¾“å‡º
    if output_details[0]['dtype'] == np.int8:
        # INT8è¾“å‡ºéœ€è¦åé‡åŒ–
        scale, zero_point = output_details[0]['quantization']
        output_data = scale * (output_data.astype(np.float32) - zero_point)
    
    return output_data[0]  # ç§»é™¤batchç»´åº¦

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # é€‰æ‹©æ¨¡å‹ (æ ¹æ®éœ€æ±‚æ›´æ¢è·¯å¾„)
    model_path = "tflite_models/emotion_model_dynamic.tflite"  # æ¨è
    # model_path = "tflite_models/emotion_model_int8.tflite"   # ç§»åŠ¨ç«¯
    
    # åŠ è½½æ¨¡å‹
    interpreter = load_tflite_model(model_path)
    
    # å‡†å¤‡æµ‹è¯•æ•°æ® (48x48ç°åº¦å›¾åƒ)
    test_image = np.random.random((48, 48, 1))
    
    # é¢„æµ‹
    predictions = predict_emotion(interpreter, test_image)
    
    # è§£é‡Šç»“æœ
    emotions = ['æ„¤æ€’', 'åŒæ¶', 'ææƒ§', 'å¼€å¿ƒ', 'æ‚²ä¼¤', 'æƒŠè®¶', 'ä¸­æ€§']
    predicted_emotion = emotions[np.argmax(predictions)]
    confidence = np.max(predictions)
    
    print(f"é¢„æµ‹è¡¨æƒ…: {predicted_emotion}")
    print(f"ç½®ä¿¡åº¦: {confidence:.2%}")

if __name__ == "__main__":
    main()
```

### JavaScript/Webæ¨ç†ä»£ç 

```javascript
// åŠ è½½TensorFlow.js
// <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>

async function loadTFLiteModel(modelUrl) {
    // ä½¿ç”¨åŠ¨æ€é‡åŒ–æ¨¡å‹ (æ¨èWebç«¯)
    const model = await tf.loadLayersModel(modelUrl);
    return model;
}

function predictEmotion(model, imageData) {
    // imageDataåº”è¯¥æ˜¯48x48çš„å›¾åƒæ•°æ®
    const tensor = tf.browser.fromPixels(imageData, 1)  // ç°åº¦
        .resizeNearestNeighbor([48, 48])
        .expandDims(0)
        .div(255.0);
    
    const predictions = model.predict(tensor);
    const probabilities = predictions.dataSync();
    
    const emotions = ['æ„¤æ€’', 'åŒæ¶', 'ææƒ§', 'å¼€å¿ƒ', 'æ‚²ä¼¤', 'æƒŠè®¶', 'ä¸­æ€§'];
    const maxIndex = probabilities.indexOf(Math.max(...probabilities));
    
    return {
        emotion: emotions[maxIndex],
        confidence: probabilities[maxIndex],
        allProbabilities: probabilities
    };
}
```

## ğŸ“± ç§»åŠ¨ç«¯é›†æˆ

### Android (Kotlin)

```kotlin
// ä½¿ç”¨INT8é‡åŒ–æ¨¡å‹
class EmotionClassifier(context: Context) {
    private var interpreter: Interpreter
    
    init {
        val model = loadModelFile(context, "emotion_model_int8.tflite")
        interpreter = Interpreter(model)
    }
    
    fun predict(bitmap: Bitmap): String {
        val input = preprocessImage(bitmap)
        val output = Array(1) { ByteArray(7) }  // INT8è¾“å‡º
        
        interpreter.run(input, output)
        
        val emotions = arrayOf("æ„¤æ€’", "åŒæ¶", "ææƒ§", "å¼€å¿ƒ", "æ‚²ä¼¤", "æƒŠè®¶", "ä¸­æ€§")
        val maxIndex = output[0].indexOf(output[0].maxOrNull()!!)
        return emotions[maxIndex]
    }
}
```

### iOS (Swift)

```swift
// ä½¿ç”¨INT8é‡åŒ–æ¨¡å‹
import TensorFlowLite

class EmotionClassifier {
    private var interpreter: Interpreter
    
    init() throws {
        guard let modelPath = Bundle.main.path(forResource: "emotion_model_int8", ofType: "tflite") else {
            throw ClassifierError.invalidModel
        }
        interpreter = try Interpreter(modelPath: modelPath)
        try interpreter.allocateTensors()
    }
    
    func predict(image: UIImage) throws -> String {
        let inputData = preprocessImage(image)
        try interpreter.copy(inputData, toInputAt: 0)
        try interpreter.invoke()
        
        let outputTensor = try interpreter.output(at: 0)
        let results = outputTensor.data
        
        let emotions = ["æ„¤æ€’", "åŒæ¶", "ææƒ§", "å¼€å¿ƒ", "æ‚²ä¼¤", "æƒŠè®¶", "ä¸­æ€§"]
        // å¤„ç†INT8è¾“å‡º...
        return emotions[maxIndex]
    }
}
```

## âš¡ æ€§èƒ½å¯¹æ¯”

| æ¨¡å‹ | æ¨ç†é€Ÿåº¦ | å†…å­˜å ç”¨ | ç²¾åº¦ | æœ€é€‚åœºæ™¯ |
|------|----------|----------|------|----------|
| Dynamic | 0.90ms | ä½ | é«˜ | WebæœåŠ¡å™¨ |
| INT8 | 0.84ms | æœ€ä½ | é«˜ | ç§»åŠ¨åº”ç”¨ |
| Basic | 1.28ms | ä¸­ | æœ€é«˜ | é«˜ç²¾åº¦éœ€æ±‚ |
| Float16 | 1.02ms | ä¸­ä½ | é«˜ | GPUæ¨ç† |

## ğŸ”§ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼Ÿ
**A**: æ ¹æ®éƒ¨ç½²ç¯å¢ƒé€‰æ‹©ï¼š
- Web/æœåŠ¡å™¨: `emotion_model_dynamic.tflite`
- æ‰‹æœºApp: `emotion_model_int8.tflite`
- é«˜ç²¾åº¦åœºæ™¯: `emotion_model_basic.tflite`

### Q: INT8æ¨¡å‹éœ€è¦ç‰¹æ®Šå¤„ç†å—ï¼Ÿ
**A**: æ˜¯çš„ï¼ŒINT8æ¨¡å‹çš„è¾“å…¥è¾“å‡ºéƒ½æ˜¯int8æ ¼å¼ï¼Œéœ€è¦é¢å¤–çš„é‡åŒ–/åé‡åŒ–æ­¥éª¤ã€‚

### Q: å“ªä¸ªæ¨¡å‹æœ€å°ï¼Ÿ
**A**: `emotion_model_dynamic.tflite` (0.68MB) å’Œ `emotion_model_int8.tflite` (0.69MB) å¤§å°æ¥è¿‘ï¼Œéƒ½å¾ˆé€‚åˆç§»åŠ¨ç«¯ã€‚

### Q: ç²¾åº¦ä¼šæŸå¤±å—ï¼Ÿ
**A**: æ‰€æœ‰é‡åŒ–æ¨¡å‹çš„é¢„æµ‹ç±»åˆ«ä¸€è‡´æ€§éƒ½æ˜¯100%ï¼Œç²¾åº¦æŸå¤±éå¸¸å°(<4%)ã€‚

## ğŸ“š æ›´å¤šèµ„æº

- [H5åˆ°TFLiteå…¼å®¹æ€§åˆ†ææŠ¥å‘Š](./H5åˆ°TFLiteå…¼å®¹æ€§åˆ†ææŠ¥å‘Š.md) - è¯¦ç»†çš„æ€§èƒ½åˆ†æ
- [æ¨¡å‹å‡†ç¡®æ€§æµ‹è¯•æŠ¥å‘Š](./æ¨¡å‹å‡†ç¡®æ€§æµ‹è¯•æŠ¥å‘Š.md) - åŸå§‹æ¨¡å‹æ€§èƒ½
- [Webæ¼”ç¤ºåº”ç”¨](./web_demo.py) - å®Œæ•´çš„Webåº”ç”¨ç¤ºä¾‹

---

ğŸ’¡ **æç¤º**: å»ºè®®ä¼˜å…ˆä½¿ç”¨ `emotion_model_dynamic.tflite`ï¼Œå®ƒæä¾›äº†æœ€ä½³çš„æ€§èƒ½ã€ç²¾åº¦å’Œå¤§å°å¹³è¡¡ã€‚ 